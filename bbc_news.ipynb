{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "First, we import the libraries that we need using \"import\".\n",
    "\n",
    "Note: All these libraries need to be downloaded beforehand if not using Google Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare our dataset\n",
    "\n",
    "we need to load the dataset in Python. \n",
    "I load it locally from the hard drive, you need to copy the bbc folder and paste it in category_path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"business\",\"entertainment\",\"politics\",\"sport\",\"tech\"]\n",
    "news_list = []\n",
    "news_category = []\n",
    "\n",
    "for folder in categories:\n",
    "    category_path = 'C:/Users/mmat/OneDrive/Desktop/Application of ML/coursework/datasets_coursework1/bbc/'+ folder +'/'\n",
    "    files = os.listdir(category_path)\n",
    "    for text in files:\n",
    "        text_path = category_path + \"/\" + text\n",
    "        with open(text_path, errors = 'replace') as t:\n",
    "            data = t.readlines()\n",
    "        data = ' '.join(data)\n",
    "        news_list.append(data)\n",
    "        news_category.append(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here you need the same link as above but replace 'bbc/' to 'bbc.csv', then paste it in df.to_csv and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>article</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profit\\n \\n Quarter...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar gains on Greenspan speech\\n \\n The doll...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos unit buyer faces loan claim\\n \\n The own...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>High fuel prices hit BA's profits\\n \\n British...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n \\n Shares ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>2220</td>\n",
       "      <td>BT program to beat dialler scams\\n \\n BT is in...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>2221</td>\n",
       "      <td>Spam e-mails tempt net shoppers\\n \\n Computer ...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>2222</td>\n",
       "      <td>Be careful how you code\\n \\n A new European di...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>2223</td>\n",
       "      <td>US cyber security chief resigns\\n \\n The man m...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>2224</td>\n",
       "      <td>Losing yourself in online gaming\\n \\n Online r...</td>\n",
       "      <td>tech</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                            article  category  \\\n",
       "0         0  Ad sales boost Time Warner profit\\n \\n Quarter...  business   \n",
       "1         1  Dollar gains on Greenspan speech\\n \\n The doll...  business   \n",
       "2         2  Yukos unit buyer faces loan claim\\n \\n The own...  business   \n",
       "3         3  High fuel prices hit BA's profits\\n \\n British...  business   \n",
       "4         4  Pernod takeover talk lifts Domecq\\n \\n Shares ...  business   \n",
       "...     ...                                                ...       ...   \n",
       "2220   2220  BT program to beat dialler scams\\n \\n BT is in...      tech   \n",
       "2221   2221  Spam e-mails tempt net shoppers\\n \\n Computer ...      tech   \n",
       "2222   2222  Be careful how you code\\n \\n A new European di...      tech   \n",
       "2223   2223  US cyber security chief resigns\\n \\n The man m...      tech   \n",
       "2224   2224  Losing yourself in online gaming\\n \\n Online r...      tech   \n",
       "\n",
       "      category_id  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "2220            4  \n",
       "2221            4  \n",
       "2222            4  \n",
       "2223            4  \n",
       "2224            4  \n",
       "\n",
       "[2225 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_csv = {'article':news_list, 'category':news_category}\n",
    "df = pd.DataFrame(news_csv)\n",
    "df.to_csv('C:/Users/mmat/OneDrive/Desktop/Application of ML/coursework/datasets_coursework1/bbc.csv')\n",
    "data = pd.read_csv('C:/Users/mmat/OneDrive/Desktop/Application of ML/coursework/datasets_coursework1/bbc.csv')\n",
    "data= data[data['article'].notnull()]\n",
    "data['category_id'] = data['category'].factorize()[0]\n",
    "columns_list = ['index','article', 'category', 'category_id']\n",
    "data.columns = columns_list\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing our dataset\n",
    " \n",
    "Preprocess the texts with nltk in few steps.\n",
    "this is original text before preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the # if you would like to see the changes to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data['article'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#download the data if needed\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All not English words will remove from the dataset, including spaces and full stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "data['BoW'] = data['article'].apply(lambda x: ' '.join([word for word in x.split() \n",
    "                                                                          if word not in (stopwords)]))\n",
    "#print(data['BoW'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing morphological affixes from words, leaving only the stem word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "ps = PorterStemmer()\n",
    "data['BoW'] = data['BoW'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
    "#print(data['BoW'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the uppercase letters to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform every capital letter to small letter\n",
    "data['BoW'] = data['BoW'].apply(lambda x: ' '.join(x.lower() for x in x.split()))\n",
    "#print(data['BoW'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all the non-word characters from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BoW'] = data['BoW'].str.replace('[^\\w\\s]','')\n",
    "#print(data['BoW'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the article into words and counted each word’s frequency then make a list of the fewer frequency words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = pd.Series(' '.join(data['BoW']).split()).value_counts()\n",
    "\n",
    "less_frequency = list(frequency[frequency <= 3].index.values)\n",
    "#less_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this step takes a bit long running time. it is to remove the less frequency words from our Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['BoW'] = data['BoW'].apply(lambda x: ' '.join([word for word in x.split() if word not in (less_frequency)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, here our preprocessed dataset ready for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['index', 'category', 'category_id', 'BoW']]\n",
    "#print(data['BoW'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering\n",
    "\n",
    "I used tfidf vectorizer for feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform our Bag of Words to feature array to use it in feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2))\n",
    "features = tf_idf.fit_transform(data.BoW).toarray()\n",
    "labels = data.category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id_df = data[['category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'category']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "I used chi-squared test to train the data with each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 'business':\n",
      "  . Top Unigram words:\n",
      "       . economi\n",
      "       . profit\n",
      "       . oil\n",
      "       . growth\n",
      "       . bank\n",
      "  . Top Bigram words:\n",
      "       . oil price\n",
      "       . econom growth\n",
      "       . interest rate\n",
      "       . analyst said\n",
      "       . stock market\n",
      "- 'entertainment':\n",
      "  . Top Unigram words:\n",
      "       . singer\n",
      "       . award\n",
      "       . actor\n",
      "       . star\n",
      "       . film\n",
      "  . Top Bigram words:\n",
      "       . lo angel\n",
      "       . name best\n",
      "       . best film\n",
      "       . the film\n",
      "       . box offic\n",
      "- 'politics':\n",
      "  . Top Unigram words:\n",
      "       . elect\n",
      "       . parti\n",
      "       . blair\n",
      "       . tori\n",
      "       . labour\n",
      "  . Top Bigram words:\n",
      "       . michael howard\n",
      "       . mr brown\n",
      "       . lib dem\n",
      "       . toni blair\n",
      "       . mr blair\n",
      "- 'sport':\n",
      "  . Top Unigram words:\n",
      "       . chelsea\n",
      "       . match\n",
      "       . champion\n",
      "       . coach\n",
      "       . cup\n",
      "  . Top Bigram words:\n",
      "       . champion leagu\n",
      "       . world cup\n",
      "       . australian open\n",
      "       . grand slam\n",
      "       . six nation\n",
      "- 'tech':\n",
      "  . Top Unigram words:\n",
      "       . digit\n",
      "       . softwar\n",
      "       . technolog\n",
      "       . comput\n",
      "       . user\n",
      "  . Top Bigram words:\n",
      "       . search engin\n",
      "       . oper system\n",
      "       . peopl use\n",
      "       . let peopl\n",
      "       . mobil phone\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "n = 5\n",
    "for category, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tf_idf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"- '{}':\".format(category))\n",
    "    print(\"  . Top Unigram words:\\n       . {}\".format('\\n       . '.join(unigrams[-n:])))\n",
    "    print(\"  . Top Bigram words:\\n       . {}\".format('\\n       . '.join(bigrams[-n:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "here i tried four diffrent models to choose the one with high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.757303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.793258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.764045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.844944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.869663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0.961798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.941573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.975281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>4</td>\n",
       "      <td>0.982022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.964045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.964045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.984270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0</td>\n",
       "      <td>0.743820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.815730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>4</td>\n",
       "      <td>0.842697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  fold_idx  accuracy\n",
       "0   RandomForestClassifier         0  0.757303\n",
       "1   RandomForestClassifier         1  0.793258\n",
       "2   RandomForestClassifier         2  0.764045\n",
       "3   RandomForestClassifier         3  0.844944\n",
       "4   RandomForestClassifier         4  0.869663\n",
       "5            MultinomialNB         0  0.961798\n",
       "6            MultinomialNB         1  0.950562\n",
       "7            MultinomialNB         2  0.941573\n",
       "8            MultinomialNB         3  0.975281\n",
       "9            MultinomialNB         4  0.982022\n",
       "10      LogisticRegression         0  0.964045\n",
       "11      LogisticRegression         1  0.964045\n",
       "12      LogisticRegression         2  0.964045\n",
       "13      LogisticRegression         3  0.984270\n",
       "14      LogisticRegression         4  0.991011\n",
       "15  DecisionTreeClassifier         0  0.743820\n",
       "16  DecisionTreeClassifier         1  0.815730\n",
       "17  DecisionTreeClassifier         2  0.737079\n",
       "18  DecisionTreeClassifier         3  0.815730\n",
       "19  DecisionTreeClassifier         4  0.842697"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    DecisionTreeClassifier(random_state=0) ]\n",
    "\n",
    "CV = 5\n",
    "cross_val_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "    for fold_idx, accuracy in enumerate(accuracies):\n",
    "        entries.append((model_name, fold_idx, accuracy))\n",
    "cross_val_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "cross_val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing\n",
    "as Logistic regression has the higher accuracy, it has been the selected model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "    features,labels, data.index, test_size=0.33, random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       173\n",
      "           1       1.00      0.97      0.98       123\n",
      "           2       0.96      0.96      0.96       140\n",
      "           3       1.00      0.99      1.00       173\n",
      "           4       0.95      0.96      0.95       126\n",
      "\n",
      "    accuracy                           0.97       735\n",
      "   macro avg       0.97      0.97      0.97       735\n",
      "weighted avg       0.97      0.97      0.97       735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examinig the model\n",
    "\n",
    "here you can write or copy-paste any articles or titles and it will give you their categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . ' Virtual musicians play interactive gig.'\n",
      "  - Predicted as: 'entertainment'\n",
      "\n",
      "2 . 'China's economy grows 18.3% in post-Covid comeback.'\n",
      "  - Predicted as: 'business'\n",
      "\n",
      "3 . 'FA Cup: Watch all Chelsea's goals from their journey to the semi-finals'\n",
      "  - Predicted as: 'sport'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\" Virtual musicians play interactive gig.\",\n",
    "         \"China's economy grows 18.3% in post-Covid comeback.\",\n",
    "         \"FA Cup: Watch all Chelsea's goals from their journey to the semi-finals\"]\n",
    "\n",
    "text_features = tf_idf.transform(texts)\n",
    "predictions = model.predict(text_features)\n",
    "n = 0\n",
    "for text, predicted in zip(texts, predictions):\n",
    "    n = n+1\n",
    "    print(n,\". '{}'\".format(text))\n",
    "    print(\"  - Predicted as: '{}'\".format(id_to_category[predicted]))\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
